vmaccepteula
install --firstdisk=usb --overwritevmfs --novmfsondisk
reboot

%include /tmp/rootpass
%include /tmp/networkconfig

%pre --interpreter=busybox

# ---> START EDIT HERE <--- #
VSAN_DISK_TYPE="AF"
PHOTON_IP="192.168.1.10"
PHOTON_CIDR="24"
PHOTON_GATEWAY="192.168.1.1"
PHOTON_DNS="192.168.1.1"
ESXI_IP="192.168.1.100"
ESXI_PASSWORD="VMware1!"
ESXI_NETMASK="255.255.255.0"
ESXI_GATEWAY="192.168.1.1"
ESXI_HOSTNAME="nuc.primp-industries.com"
ESXI_DNS="192.168.1.1"
VCSA_IP="192.168.1.200"
VCSA_HOSTNAME="192.168.1.200"
VCSA_PREFIX="24"
VCSA_GATEWAY="192.168.1.1"
VCSA_DNS="192.168.1.1"
VCSA_SSO_DOMAIN_NAME="vsphere.local"
VCSA_SSO_SITE_NAME="virtuallyGhetto"
VCSA_ROOT_PASSWORD="VMware1!"
VCSA_SSO_PASSWORD="VMware1!"
VCSA_SSH_ENABLED="true"
VCSA_CEIP_ENABLED="true"
VCSA_DATACENTER_NAME="VSAN-Datacenter"
VCSA_CLUSTER_NAME="VSAN-Cluster"
VCSA_WEBCLIENT_THEME_NAME="CormacHogan"
# ---> STOP EDIT HERE  <--- #

echo "network --bootproto=static --ip=${ESXI_IP} --netmask=${ESXI_NETMASK} --gateway=${ESXI_GATEWAY} --hostname=${ESXI_HOSTNAME} --nameserver=${ESXI_DNS} --addvmportgroup=1" > /tmp/networkconfig
echo "rootpw ${ESXI_PASSWORD}" > /tmp/rootpass
echo "${VSAN_DISK_TYPE}" > /tmp/vsandisktype

cat > /tmp/deployvmsettings << __DEPLOYVM__
PHOTON_IP=${PHOTON_IP}
PHOTON_CIDR=${PHOTON_CIDR}
PHOTON_GATEWAY=${PHOTON_GATEWAY}
PHOTON_DNS=${PHOTON_DNS}
ESXI_IP=${ESXI_IP}
ESXI_PASSWORD=${ESXI_PASSWORD}
VCSA_IP=${VCSA_IP}
VCSA_HOSTNAME=${VCSA_HOSTNAME}
VCSA_PREFIX=${VCSA_PREFIX}
VCSA_GATEWAY=${VCSA_GATEWAY}
VCSA_DNS=${VCSA_DNS}
VCSA_SSO_DOMAIN_NAME=${VCSA_SSO_DOMAIN_NAME}
VCSA_SSO_SITE_NAME=${VCSA_SSO_SITE_NAME}
VCSA_ROOT_PASSWORD=${VCSA_ROOT_PASSWORD}
VCSA_SSO_PASSWORD=${VCSA_SSO_PASSWORD}
VCSA_SSH_ENABLED=${VCSA_SSH_ENABLED}
VCSA_CEIP_ENABLED=${VCSA_CEIP_ENABLED}
VCSA_DATACENTER_NAME=${VCSA_DATACENTER_NAME}
VCSA_CLUSTER_NAME=${VCSA_CLUSTER_NAME}
VCSA_WEBCLIENT_THEME_NAME=${VCSA_WEBCLIENT_THEME_NAME}
__DEPLOYVM__

%pre --interpreter=python

import subprocess, os, uuid, syslog

vsan_syslog_key = "VSAN-KS"
debug = False

with open ("/tmp/vsandisktype", "r") as myfile:
    vsan_disk_type=myfile.read().replace('\n', '')

def execute(cmd,shell):
    proc = subprocess.Popen(cmd, shell=shell, stdout=subprocess.PIPE)
    return proc.communicate()[0].decode()

# Enable vSAN traffic
def enableVsanTraffic():
  vsan_traffic_cmd = "localcli vsan network ip add -i vmk0"
  syslog.syslog(vsan_syslog_key + " Enabling vSAN traffic on vmk0: " + vsan_traffic_cmd)
  if debug == False:
    os.system(vsan_traffic_cmd)

# Enable Dedupe/Compression
def enableDedupeCompression():
  space_eff_cmd = "localcli system settings advanced set -o /VSAN/StorageEfficiency -i 1"
  syslog.syslog(vsan_syslog_key + " Enabling vSAN Dedupe/Compression command: " + space_eff_cmd)
  if debug == False:
    os.system(space_eff_cmd)

# Build VSAN Disk Group command based on vdq -q output
def createVsanAFDiskGroup():
	output = execute(['/sbin/vdq','-q'],False)

	capacityDisk = None
	cachingDisk = None
	largestDisk = None
	largestDiskSize = None
	usbDevice = None

	results = eval(output)
	for disk in results:
		diskId = disk['Name']

		if disk['State'] == 'Eligible for use by VSAN':
			syslog.syslog(vsan_syslog_key + " Found Disk: " + diskId)

			diskcapacity_cmd = "localcli storage core device capacity list -d " + diskId + " | tail -1 | awk '{print $5}'"
			syslog.syslog(vsan_syslog_key + " Running disk capacity command: " + diskcapacity_cmd)
			ps = subprocess.Popen(diskcapacity_cmd,shell=True,stdout=subprocess.PIPE,stderr=subprocess.STDOUT)
			strdiskSize = ps.communicate()[0].decode().strip()
			diskSize = int(strdiskSize)
			if largestDisk == None:
				largestDisk = diskId
				largestDiskSize = diskSize
			else:
				if diskSize > largestDiskSize:
					capacityDisk = diskId
					cachingDisk = largestDisk
				else:
					capacityDisk = largestDisk
					cachingDisk = diskId

			syslog.syslog(vsan_syslog_key + " Largest Capacity Disk so far: " + largestDisk + " (" + str(largestDiskSize) + ")")

		if disk['State'] == 'Ineligible for use by VSAN' and disk['VSANUUID'] == "":
			usbDevice = diskId
			fo = open("/tmp/usbDevice.txt", "w")
			fo.write(usbDevice)
			fo.close()

	if cachingDisk != None and capacityDisk != None:
		# Tag Capacity Disk
		disktag_cmd = "localcli vsan storage tag add -d " + capacityDisk + " -t capacityFlash"
		syslog.syslog(vsan_syslog_key + " Running disk capacity tagging command: " + disktag_cmd)
		if debug == False:
			os.system(disktag_cmd)

		# Create VSAN Disk Group
		diskgroup_cmd = "localcli vsan storage add -s " + cachingDisk + " -d " + capacityDisk
		syslog.syslog(vsan_syslog_key + " Running disk group create command: " + diskgroup_cmd)
		if debug == False:
			os.system(diskgroup_cmd)

def createVsanHybridDiskGroup():
	output = execute(['/sbin/vdq','-q'],False)

	capacityDisk = None
	cachingDisk = None
	largestDisk = None
	largestDiskSize = None
	usbDevice = None

	results = eval(output)
	for disk in results:
		diskId = disk['Name']

		if disk['State'] == 'Eligible for use by VSAN':
			syslog.syslog(vsan_syslog_key + " Found Disk: " + diskId)

			diskcapacity_cmd = "localcli storage core device capacity list -d " + diskId + " | tail -1 | awk '{print $5}'"
			syslog.syslog(vsan_syslog_key + " Running disk capacity command: " + diskcapacity_cmd)
			ps = subprocess.Popen(diskcapacity_cmd,shell=True,stdout=subprocess.PIPE,stderr=subprocess.STDOUT)

			if disk['IsSSD'] == '1':
				syslog.syslog(vsan_syslog_key + " Found SSD " + diskId)
				cachingDisk = diskId

			if disk['IsSSD'] == '0':
				syslog.syslog(vsan_syslog_key + " Found HDD " + diskId)
				capacityDisk = diskId

		if disk['State'] == 'Ineligible for use by VSAN' and disk['VSANUUID'] == "":
			usbDevice = diskId
			fo = open("/tmp/usbDevice.txt", "w")
			fo.write(usbDevice)
			fo.close()

	if cachingDisk != None and capacityDisk != None:
		# Create VSAN Disk Group
		diskgroup_cmd = "localcli vsan storage add -s " + cachingDisk + " -d " + capacityDisk
		syslog.syslog(vsan_syslog_key + " Running disk group create command: " + diskgroup_cmd)
		if debug == False:
			os.system(diskgroup_cmd)

def createVsanCluster():
	cluster_cmd = "localcli vsan cluster new"
	syslog.syslog(vsan_syslog_key + " Running VSAN cluster create command: " + cluster_cmd)
	if debug == False:
		os.system(cluster_cmd)

enableVsanTraffic()
if vsan_disk_type == "HYBRID":
	createVsanHybridDiskGroup()
else:
	createVsanAFDiskGroup()
	enableDedupeCompression()
createVsanCluster()

%pre --interpreter=busybox

/bin/vmkload_mod vmfs3

# Set FTT=0 + Force Provisioning for single node
localcli vsan policy setdefault -c vdisk -p "((\"hostFailuresToTolerate\" i1) (\"forceProvisioning\" i1))"
localcli vsan policy setdefault -c vmnamespace -p "((\"hostFailuresToTolerate\" i1) (\"forceProvisioning\" i1))"

# Copy Deploy VM to vSAN Datastore
USB_KEY=$(cat /tmp/usbDevice.txt)
DEPLOY_VM_ZIP=DeployVM.zip
VCSA_ISO=VCSA.iso

# required in case where osfs-mkdir may fail
sleep 120

/usr/lib/vmware/osfs/bin/osfs-mkdir /vmfs/volumes/vsanDatastore/DeployVM
/bin/mcopy -i "/dev/disks/${USB_KEY}:2" ::/${DEPLOY_VM_ZIP} /vmfs/volumes/vsanDatastore/DeployVM/${DEPLOY_VM_ZIP}
/bin/mcopy -i "/dev/disks/${USB_KEY}:2" ::/VCSA-part-aa /vmfs/volumes/vsanDatastore/DeployVM/VCSA-part-aa
/bin/mcopy -i "/dev/disks/${USB_KEY}:2" ::/VCSA-part-ab /vmfs/volumes/vsanDatastore/DeployVM/VCSA-part-ab
/bin/mcopy -i "/dev/disks/${USB_KEY}:2" ::/VCSA-part-ac /vmfs/volumes/vsanDatastore/DeployVM/VCSA-part-ac
/bin/mcopy -i "/dev/disks/${USB_KEY}:2" ::/VCSA-part-ad /vmfs/volumes/vsanDatastore/DeployVM/VCSA-part-ad
cat /vmfs/volumes/vsanDatastore/DeployVM/VCSA-part-a* > /vmfs/volumes/vsanDatastore/DeployVM/${VCSA_ISO}
unzip /vmfs/volumes/vsanDatastore/DeployVM/${DEPLOY_VM_ZIP} -d /vmfs/volumes/vsanDatastore/DeployVM
rm -f /vmfs/volumes/vsanDatastore/DeployVM/VCSA-part-a*
rm -f /vmfs/volumes/vsanDatastore/DeployVM/${DEPLOY_VM_ZIP}

# Custom values passed to DeployVM
. /tmp/deployvmsettings

# Add guestinfo properties to Deploy VM for VCSA deployment
DEPLOYVM_VMX_PATH=/vmfs/volumes/vsanDatastore/DeployVM/DeployVM.vmx

echo "guestinfo.photon_ip = \"${PHOTON_IP}\"" >> ${DEPLOYVM_VMX_PATH}
echo "guestinfo.photon_cidr = \"${PHOTON_CIDR}\"" >> ${DEPLOYVM_VMX_PATH}
echo "guestinfo.photon_gateway = \"${PHOTON_GATEWAY}\"" >> ${DEPLOYVM_VMX_PATH}
echo "guestinfo.photon_dns = \"${PHOTON_DNS}\"" >> ${DEPLOYVM_VMX_PATH}
echo "guestinfo.esxi_hostname = \"${ESXI_IP}\"" >> ${DEPLOYVM_VMX_PATH}
echo "guestinfo.esxi_password = \"${ESXI_PASSWORD}\"" >> ${DEPLOYVM_VMX_PATH}
echo "guestinfo.vcsa_ip = \"${VCSA_IP}\"" >> ${DEPLOYVM_VMX_PATH}
echo "guestinfo.vcsa_dns = \"${VCSA_DNS}\"" >> ${DEPLOYVM_VMX_PATH}
echo "guestinfo.vcsa_prefix = \"${VCSA_PREFIX}\"" >> ${DEPLOYVM_VMX_PATH}
echo "guestinfo.vcsa_gateway = \"${VCSA_GATEWAY}\"" >> ${DEPLOYVM_VMX_PATH}
echo "guestinfo.vcsa_hostname = \" ${VCSA_HOSTNAME}\"" >> ${DEPLOYVM_VMX_PATH}
echo "guestinfo.vcsa_sso_domain_name = \"${VCSA_SSO_DOMAIN_NAME}\"" >> ${DEPLOYVM_VMX_PATH}
echo "guestinfo.vcsa_sso_site_name = \"${VCSA_SSO_SITE_NAME}\"" >> ${DEPLOYVM_VMX_PATH}
echo "guestinfo.vcsa_root_password = \"${VCSA_ROOT_PASSWORD}\"" >> ${DEPLOYVM_VMX_PATH}
echo "guestinfo.vcsa_sso_password = \"${VCSA_SSO_PASSWORD}\"" >> ${DEPLOYVM_VMX_PATH}
echo "guestinfo.vcsa_ssh_enabled = \"${VCSA_SSH_ENABLED}\"" >> ${DEPLOYVM_VMX_PATH}
echo "guestinfo.vcsa_ceip_enabled = \"${VCSA_CEIP_ENABLED}\"" >> ${DEPLOYVM_VMX_PATH}
echo "guestinfo.vcsa_datacenter_name = \"${VCSA_DATACENTER_NAME}\"" >> ${DEPLOYVM_VMX_PATH}
echo "guestinfo.vcsa_cluster_name = \"${VCSA_CLUSTER_NAME}\"" >> ${DEPLOYVM_VMX_PATH}
echo "guestinfo.vcsa_webclient_theme_name = \"${VCSA_WEBCLIENT_THEME_NAME}\"" >> ${DEPLOYVM_VMX_PATH}

# Update the Deploy VM VMX file w/VSAN path
VSAN_VOLUME=$(ls /vmfs/volumes/ | grep "vsan:")
sed -i "s#BLAH#${VSAN_VOLUME}#g" ${DEPLOYVM_VMX_PATH}

%post --interpreter=busybox

# Disable AHCI Native Driver (known to have issues for NUCs)
localcli system module set --enabled=false --module=vmw_ahci

# Disable device monitoring for Home Labs
localcli system settings advanced set -o /LSOM/VSANDeviceMonitoring -i 0

# Enable Thin swap
localcli system settings advanced set -o /VSAN/SwapThickProvisionDisabled -i 1

# Required if you plan to run Nested ESXi on top of vSAN Datatsore
localcli system settings advanced set -o /VSAN/FakeSCSIReservations -i 1

%firstboot --interpreter=busybox

DEPLOYVM_VMX_PATH=/vmfs/volumes/vsanDatastore/DeployVM/DeployVM.vmx

# Ensure hostd is ready
while ! vim-cmd hostsvc/runtimeinfo; do
sleep 10
done

# Set FTT=0 + Force Provisioning for single node
esxcli vsan policy setdefault -c vdisk -p "((\"hostFailuresToTolerate\" i1) (\"forceProvisioning\" i1))"
esxcli vsan policy setdefault -c vmnamespace -p "((\"hostFailuresToTolerate\" i1) (\"forceProvisioning\" i1))"

# enable & start SSH
vim-cmd hostsvc/enable_ssh
vim-cmd hostsvc/start_ssh

# enable & start ESXi Shell
vim-cmd hostsvc/enable_esx_shell
vim-cmd hostsvc/start_esx_shell

# Suppress ESXi Shell warning
esxcli system settings advanced set -o /UserVars/SuppressShellWarning -i 1

# Register VM
vim-cmd solo/registervm ${DEPLOYVM_VMX_PATH}

# power on VM
vim-cmd vmsvc/power.on 1
